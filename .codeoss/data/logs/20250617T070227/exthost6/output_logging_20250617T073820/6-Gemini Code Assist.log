I0617 07:38:52.921318    6164 serve.go:43] cloudcode_cli (May  8 2025 07:59:00 -0700, cl:756312233 baseline:755919187)
I0617 07:38:52.922528    6164 serve.go:44] Command line: ["/home/f43939714/.cache/cloud-code/cloudcode_cli/cloudcode_cli/82761e7f/cloudcode_cli" "duet" "-trace" "-logtostderr"]
I0617 07:38:52.922606    6164 server.go:348] tracing on
I0617 07:38:52.926451    6164 server.go:764] jsonrpc2: --> request #0: initialize: {"processId":4924,"clientInfo":{"name":"Code OSS for Cloud Shell","version":"1.99.3-cde"},"locale":"en","rootPath":"/home/f43939714/cloudshell_open/python-docs-samples","rootUri":"file:///home/f43939714/cloudshell_open/python-docs-samples","capabilities":{"workspace":{"applyEdit":true,"workspaceEdit":{"documentChanges":true,"resourceOperations":["create","rename","delete"],"failureHandling":"textOnlyTransactional","normalizesLineEndings":true,"changeAnnotationSupport":{"groupsOnLabel":true}},"configuration":true,"didChangeWatchedFiles":{"dynamicRegistration":true,"relativePatternSupport":true},"symbol":{"dynamicRegistration":true,"symbolKind":{"valueSet":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]},"tagSupport":{"valueSet":[1]},"resolveSupport":{"properties":["location.range"]}},"codeLens":{"refreshSupport":true},"executeCommand":{"dynamicRegistration":true},"didChangeConfiguration":{"dynamicRegistration":true},"workspaceFolders":true,"foldingRange":{"refreshSupport":true},"semanticTokens":{"refreshSupport":true},"fileOperations":{"dynamicRegistration":true,"didCreate":true,"didRename":true,"didDelete":true,"willCreate":true,"willRename":true,"willDelete":true},"inlineValue":{"refreshSupport":true},"inlayHint":{"refreshSupport":true},"diagnostics":{"refreshSupport":true}},"textDocument":{"publishDiagnostics":{"relatedInformation":true,"versionSupport":false,"tagSupport":{"valueSet":[1,2]},"codeDescriptionSupport":true,"dataSupport":true},"synchronization":{"dynamicRegistration":true,"willSave":true,"willSaveWaitUntil":true,"didSave":true},"completion":{"dynamicRegistration":true,"contextSupport":true,"completionItem":{"snippetSupport":true,"commitCharactersSupport":true,"documentationFormat":["markdown","plaintext"],"deprecatedSupport":true,"preselectSupport":true,"tagSupport":{"valueSet":[1]},"insertReplaceSupport":true,"resolveSupport":{"properties":["documentation","detail","additionalTextEdits"]},"insertTextModeSupport":{"valueSet":[1,2]},"labelDetailsSupport":true},"insertTextMode":2,"completionItemKind":{"valueSet":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]},"completionList":{"itemDefaults":["commitCharacters","editRange","insertTextFormat","insertTextMode","data"]}},"hover":{"dynamicRegistration":true,"contentFormat":["markdown","plaintext"]},"signatureHelp":{"dynamicRegistration":true,"signatureInformation":{"documentationFormat":["markdown","plaintext"],"parameterInformation":{"labelOffsetSupport":true},"activeParameterSupport":true},"contextSupport":true},"definition":{"dynamicRegistration":true,"linkSupport":true},"references":{"dynamicRegistration":true},"documentHighlight":{"dynamicRegistration":true},"documentSymbol":{"dynamicRegistration":true,"symbolKind":{"valueSet":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]},"hierarchicalDocumentSymbolSupport":true,"tagSupport":{"valueSet":[1]},"labelSupport":true},"codeAction":{"dynamicRegistration":true,"isPreferredSupport":true,"disabledSupport":true,"dataSupport":true,"resolveSupport":{"properties":["edit"]},"codeActionLiteralSupport":{"codeActionKind":{"valueSet":["","quickfix","refactor","refactor.extract","refactor.inline","refactor.rewrite","source","source.organizeImports"]}},"honorsChangeAnnotations":true},"codeLens":{"dynamicRegistration":true},"formatting":{"dynamicRegistration":true},"rangeFormatting":{"dynamicRegistration":true,"rangesSupport":true},"onTypeFormatting":{"dynamicRegistration":true},"rename":{"dynamicRegistration":true,"prepareSupport":true,"prepareSupportDefaultBehavior":1,"honorsChangeAnnotations":true},"documentLink":{"dynamicRegistration":true,"tooltipSupport":true},"typeDefinition":{"dynamicRegistration":true,"linkSupport":true},"implementation":{"dynamicRegistration":true,"linkSupport":true},"colorProvider":{"dynamicRegistration":true},"foldingRange":{"dynamicRegistration":true,"rangeLimit":5000,"lineFoldingOnly":true,"foldingRangeKind":{"valueSet":["comment","imports","region"]},"foldingRange":{"collapsedText":false}},"declaration":{"dynamicRegistration":true,"linkSupport":true},"selectionRange":{"dynamicRegistration":true},"callHierarchy":{"dynamicRegistration":true},"semanticTokens":{"dynamicRegistration":true,"tokenTypes":["namespace","type","class","enum","interface","struct","typeParameter","parameter","variable","property","enumMember","event","function","method","macro","keyword","modifier","comment","string","number","regexp","operator","decorator"],"tokenModifiers":["declaration","definition","readonly","static","deprecated","abstract","async","modification","documentation","defaultLibrary"],"formats":["relative"],"requests":{"range":true,"full":{"delta":true}},"multilineTokenSupport":false,"overlappingTokenSupport":false,"serverCancelSupport":true,"augmentsSyntaxTokens":true},"linkedEditingRange":{"dynamicRegistration":true},"typeHierarchy":{"dynamicRegistration":true},"inlineValue":{"dynamicRegistration":true},"inlayHint":{"dynamicRegistration":true,"resolveSupport":{"properties":["tooltip","textEdits","label.tooltip","label.location","label.command"]}},"diagnostic":{"dynamicRegistration":true,"relatedDocumentSupport":false}},"window":{"showMessage":{"messageActionItem":{"additionalPropertiesSupport":true}},"showDocument":{"support":true},"workDoneProgress":true},"general":{"staleRequestSupport":{"cancel":true,"retryOnContentModified":["textDocument/semanticTokens/full","textDocument/semanticTokens/range","textDocument/semanticTokens/full/delta"]},"regularExpressions":{"engine":"ECMAScript","version":"ES2020"},"markdown":{"parser":"marked","version":"1.1.0"},"positionEncodings":["utf-16"]},"notebookDocument":{"synchronization":{"dynamicRegistration":true,"executionSummarySupport":true}}},"initializationOptions":{"ideSessionIndex":"20250617_11","lsSessionIndex":0,"ideType":"CLOUD_SHELL","ideVersion":"1.99.3-cde","platform":"LINUX_AMD64","pluginVersion":"2.33.0","updateChannel":"","pluginType":"CLOUD_CODE","ideName":"Code OSS for Cloud Shell"},"trace":"off","workspaceFolders":[{"uri":"file:///home/f43939714/cloudshell_open/python-docs-samples","name":"python-docs-samples"}]}
I0617 07:38:52.929910    6164 life_cycle.go:192] Initializing. Architecture: "amd64", Operating system: "linux"
I0617 07:38:52.930395    6164 server.go:764] jsonrpc2: <-- result #0: initialize: {"capabilities":{"textDocumentSync":{"openClose":true,"change":2,"save":{"includeText":true}},"completionProvider":{},"hoverProvider":true,"signatureHelpProvider":{},"codeActionProvider":{"codeActionKinds":["quickfix"],"resolveProvider":true},"documentLinkProvider":{},"executeCommandProvider":{"commands":["_cloudcode.duetAI.ls.completionAccepted","_cloudcode.duetAI.ls.completionRejected","_cloudcode.duetAI.ls.cachedDocs","_cloudcode.duetAI.ls.updateIntellisenseCache","_cloudcode.duetAI.ls.overwriteLastEdit"]},"workspace":{"workspaceFolders":{},"fileOperations":{"didRename":{"filters":[{"scheme":"file","pattern":{"glob":"**","matches":"file"}}]},"didDelete":{"filters":[{"scheme":"file","pattern":{"glob":"**","matches":"file"}}]}}}},"serverInfo":{"name":"Gemini","version":"2.33.0"}}
I0617 07:38:52.988604    6164 server.go:764] jsonrpc2: --> notif: initialized: {}
I0617 07:38:52.988975    6164 server.go:764] jsonrpc2: <-- request #0: client/registerCapability: {"registrations":[{"id":"workspace/didChangeConfiguration","method":"workspace/didChangeConfiguration"},{"id":"workspace/didChangeWatchedFiles","method":"workspace/didChangeWatchedFiles","registerOptions":{"watchers":[{"globPattern":"**","kind":2}]}}]}
I0617 07:38:53.045874    6164 server.go:764] jsonrpc2: --> notif: textDocument/didOpen: {"textDocument":{"uri":"file:///home/f43939714/cloudshell_open/python-docs-samples/videointelligence/samples/analyze/analyze.py","languageId":"python","version":1,"text":"#!/usr/bin/env python\n\n# Copyright 2017 Google LLC.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"This application demonstrates label detection,\nexplicit content, and shot change detection using the Google Cloud API.\n\nUsage Examples:\n\n    python analyze.py labels gs://cloud-samples-data/video/chicago.mp4\n    python analyze.py labels_file resources/cat.mp4\n    python analyze.py shots gs://cloud-samples-data/video/gbikes_dinosaur.mp4\n    python analyze.py explicit_content \\\n    gs://cloud-samples-data/video/gbikes_dinosaur.mp4\n    python analyze.py text_gcs \\\n    gs://cloud-samples-data/video/googlework_tiny.mp4\n    python analyze.py text_file resources/googlework_tiny.mp4\n    python analyze.py objects_gcs gs://cloud-samples-data/video/cat.mp4\n    python analyze.py objects_file resources/cat.mp4\n\"\"\"\n\nimport argparse\n\n# [START video_detect_text]\nimport io\n\nfrom google.cloud import videointelligence\n\n# [END video_detect_text]\n\n\ndef analyze_explicit_content(path):\n    # [START video_analyze_explicit_content]\n    \"\"\"Detects explicit content from the GCS path to a video.\"\"\"\n    video_client = videointelligence.VideoIntelligenceServiceClient()\n    features = [videointelligence.Feature.EXPLICIT_CONTENT_DETECTION]\n\n    operation = video_client.annotate_video(\n        request={\"features\": features, \"input_uri\": path}\n    )\n    print(\"\\nProcessing video for explicit content annotations:\")\n\n    result = operation.result(timeout=90)\n    print(\"\\nFinished processing.\")\n\n    # Retrieve first result because a single video was processed\n    for frame in result.annotation_results[0].explicit_annotation.frames:\n        likelihood = videointelligence.Likelihood(frame.pornography_likelihood)\n        frame_time = frame.time_offset.seconds + frame.time_offset.microseconds / 1e6\n        print(\"Time: {}s\".format(frame_time))\n        print(\"\\tpornography: {}\".format(likelihood.name))\n    # [END video_analyze_explicit_content]\n\n\ndef analyze_labels(path):\n    # [START video_analyze_labels_gcs]\n    \"\"\"Detects labels given a GCS path.\"\"\"\n    video_client = videointelligence.VideoIntelligenceServiceClient()\n    features = [videointelligence.Feature.LABEL_DETECTION]\n\n    mode = videointelligence.LabelDetectionMode.SHOT_AND_FRAME_MODE\n    config = videointelligence.LabelDetectionConfig(label_detection_mode=mode)\n    context = videointelligence.VideoContext(label_detection_config=config)\n\n    operation = video_client.annotate_video(\n        request={\"features\": features, \"input_uri\": path, \"video_context\": context}\n    )\n    print(\"\\nProcessing video for label annotations:\")\n\n    result = operation.result(timeout=180)\n    print(\"\\nFinished processing.\")\n\n    # Process video/segment level label annotations\n    segment_labels = result.annotation_results[0].segment_label_annotations\n    for i, segment_label in enumerate(segment_labels):\n        print(\"Video label description: {}\".format(segment_label.entity.description))\n        for category_entity in segment_label.category_entities:\n            print(\n                \"\\tLabel category description: {}\".format(category_entity.description)\n            )\n\n        for i, segment in enumerate(segment_label.segments):\n            start_time = (\n                segment.segment.start_time_offset.seconds\n                + segment.segment.start_time_offset.microseconds / 1e6\n            )\n            end_time = (\n                segment.segment.end_time_offset.seconds\n                + segment.segment.end_time_offset.microseconds / 1e6\n            )\n            positions = \"{}s to {}s\".format(start_time, end_time)\n            confidence = segment.confidence\n            print(\"\\tSegment {}: {}\".format(i, positions))\n            print(\"\\tConfidence: {}\".format(confidence))\n        print(\"\\n\")\n\n    # Process shot level label annotations\n    shot_labels = result.annotation_results[0].shot_label_annotations\n    for i, shot_label in enumerate(shot_labels):\n        print(\"Shot label description: {}\".format(shot_label.entity.description))\n        for category_entity in shot_label.category_entities:\n            print(\n                \"\\tLabel category description: {}\".format(category_entity.description)\n            )\n\n        for i, shot in enumerate(shot_label.segments):\n            start_time = (\n                shot.segment.start_time_offset.seconds\n                + shot.segment.start_time_offset.microseconds / 1e6\n            )\n            end_time = (\n                shot.segment.end_time_offset.seconds\n                + shot.segment.end_time_offset.microseconds / 1e6\n            )\n            positions = \"{}s to {}s\".format(start_time, end_time)\n            confidence = shot.confidence\n            print(\"\\tSegment {}: {}\".format(i, positions))\n            print(\"\\tConfidence: {}\".format(confidence))\n        print(\"\\n\")\n\n    # Process frame level label annotations\n    frame_labels = result.annotation_results[0].frame_label_annotations\n    for i, frame_label in enumerate(frame_labels):\n        print(\"Frame label description: {}\".format(frame_label.entity.description))\n        for category_entity in frame_label.category_entities:\n            print(\n                \"\\tLabel category description: {}\".format(category_entity.description)\n            )\n\n        # Each frame_label_annotation has many frames,\n        # here we print information only about the first frame.\n        frame = frame_label.frames[0]\n        time_offset = frame.time_offset.seconds + frame.time_offset.microseconds / 1e6\n        print(\"\\tFirst frame time offset: {}s\".format(time_offset))\n        print(\"\\tFirst frame confidence: {}\".format(frame.confidence))\n        print(\"\\n\")\n    # [END video_analyze_labels_gcs]\n\n\ndef analyze_labels_file(path):\n    # [START video_analyze_labels]\n    \"\"\"Detect labels given a file path.\"\"\"\n    video_client = videointelligence.VideoIntelligenceServiceClient()\n    features = [videointelligence.Feature.LABEL_DETECTION]\n\n    with io.open(path, \"rb\") as movie:\n        input_content = movie.read()\n\n    operation = video_client.annotate_video(\n        request={\"features\": features, \"input_content\": input_content}\n    )\n    print(\"\\nProcessing video for label annotations:\")\n\n    result = operation.result(timeout=90)\n    print(\"\\nFinished processing.\")\n\n    # Process video/segment level label annotations\n    segment_labels = result.annotation_results[0].segment_label_annotations\n    for i, segment_label in enumerate(segment_labels):\n        print(\"Video label description: {}\".format(segment_label.entity.description))\n        for category_entity in segment_label.category_entities:\n            print(\n                \"\\tLabel category description: {}\".format(category_entity.description)\n            )\n\n        for i, segment in enumerate(segment_label.segments):\n            start_time = (\n                segment.segment.start_time_offset.seconds\n                + segment.segment.start_time_offset.microseconds / 1e6\n            )\n            end_time = (\n                segment.segment.end_time_offset.seconds\n                + segment.segment.end_time_offset.microseconds / 1e6\n            )\n            positions = \"{}s to {}s\".format(start_time, end_time)\n            confidence = segment.confidence\n            print(\"\\tSegment {}: {}\".format(i, positions))\n            print(\"\\tConfidence: {}\".format(confidence))\n        print(\"\\n\")\n\n    # Process shot level label annotations\n    shot_labels = result.annotation_results[0].shot_label_annotations\n    for i, shot_label in enumerate(shot_labels):\n        print(\"Shot label description: {}\".format(shot_label.entity.description))\n        for category_entity in shot_label.category_entities:\n            print(\n                \"\\tLabel category description: {}\".format(category_entity.description)\n            )\n\n        for i, shot in enumerate(shot_label.segments):\n            start_time = (\n                shot.segment.start_time_offset.seconds\n                + shot.segment.start_time_offset.microseconds / 1e6\n            )\n            end_time = (\n                shot.segment.end_time_offset.seconds\n                + shot.segment.end_time_offset.microseconds / 1e6\n            )\n            positions = \"{}s to {}s\".format(start_time, end_time)\n            confidence = shot.confidence\n            print(\"\\tSegment {}: {}\".format(i, positions))\n            print(\"\\tConfidence: {}\".format(confidence))\n        print(\"\\n\")\n\n    # Process frame level label annotations\n    frame_labels = result.annotation_results[0].frame_label_annotations\n    for i, frame_label in enumerate(frame_labels):\n        print(\"Frame label description: {}\".format(frame_label.entity.description))\n        for category_entity in frame_label.category_entities:\n            print(\n                \"\\tLabel category description: {}\".format(category_entity.description)\n            )\n\n        # Each frame_label_annotation has many frames,\n        # here we print information only about the first frame.\n        frame = frame_label.frames[0]\n        time_offset = frame.time_offset.seconds + frame.time_offset.microseconds / 1e6\n        print(\"\\tFirst frame time offset: {}s\".format(time_offset))\n        print(\"\\tFirst frame confidence: {}\".format(frame.confidence))\n        print(\"\\n\")\n    # [END video_analyze_labels]\n\n\ndef analyze_shots(path):\n    # [START video_analyze_shots]\n    \"\"\"Detects camera shot changes.\"\"\"\n    video_client = videointelligence.VideoIntelligenceServiceClient()\n    features = [videointelligence.Feature.SHOT_CHANGE_DETECTION]\n    operation = video_client.annotate_video(\n        request={\"features\": features, \"input_uri\": path}\n    )\n    print(\"\\nProcessing video for shot change annotations:\")\n\n    result = operation.result(timeout=90)\n    print(\"\\nFinished processing.\")\n\n    # first result is retrieved because a single video was processed\n    for i, shot in enumerate(result.annotation_results[0].shot_annotations):\n        start_time = (\n            shot.start_time_offset.seconds + shot.start_time_offset.microseconds / 1e6\n        )\n        end_time = (\n            shot.end_time_offset.seconds + shot.end_time_offset.microseconds / 1e6\n        )\n        print(\"\\tShot {}: {} to {}\".format(i, start_time, end_time))\n    # [END video_analyze_shots]\n\n\ndef speech_transcription(path):\n    # [START video_speech_transcription_gcs]\n    \"\"\"Transcribe speech from a video stored on GCS.\"\"\"\n    from google.cloud import videointelligence\n\n    video_client = videointelligence.VideoIntelligenceServiceClient()\n    features = [videointelligence.Feature.SPEECH_TRANSCRIPTION]\n\n    config = videointelligence.SpeechTranscriptionConfig(\n        language_code=\"en-US\", enable_automatic_punctuation=True\n    )\n    video_context = videointelligence.VideoContext(speech_transcription_config=config)\n\n    operation = video_client.annotate_video(\n        request={\n            \"features\": features,\n            \"input_uri\": path,\n            \"video_context\": video_context,\n        }\n    )\n\n    print(\"\\nProcessing video for speech transcription.\")\n\n    result = operation.result(timeout=600)\n\n    # There is only one annotation_result since only\n    # one video is processed.\n    annotation_results = result.annotation_results[0]\n    for speech_transcription in annotation_results.speech_transcriptions:\n        # The number of alternatives for each transcription is limited by\n        # SpeechTranscriptionConfig.max_alternatives.\n        # Each alternative is a different possible transcription\n        # and has its own confidence score.\n        for alternative in speech_transcription.alternatives:\n            print(\"Alternative level information:\")\n\n            print(\"Transcript: {}\".format(alternative.transcript))\n            print(\"Confidence: {}\\n\".format(alternative.confidence))\n\n            print(\"Word level information:\")\n            for word_info in alternative.words:\n                word = word_info.word\n                start_time = word_info.start_time\n                end_time = word_info.end_time\n                print(\n                    \"\\t{}s - {}s: {}\".format(\n                        start_time.seconds + start_time.microseconds * 1e-6,\n                        end_time.seconds + end_time.microseconds * 1e-6,\n                        word,\n                    )\n                )\n    # [END video_speech_transcription_gcs]\n\n\ndef video_detect_text_gcs(input_uri):\n    # [START video_detect_text_gcs]\n    \"\"\"Detect text in a video stored on GCS.\"\"\"\n    from google.cloud import videointelligence\n\n    video_client = videointelligence.VideoIntelligenceServiceClient()\n    features = [videointelligence.Feature.TEXT_DETECTION]\n\n    operation = video_client.annotate_video(\n        request={\"features\": features, \"input_uri\": input_uri}\n    )\n\n    print(\"\\nProcessing video for text detection.\")\n    result = operation.result(timeout=600)\n\n    # The first result is retrieved because a single video was processed.\n    annotation_result = result.annotation_results[0]\n\n    for text_annotation in annotation_result.text_annotations:\n        print(\"\\nText: {}\".format(text_annotation.text))\n\n        # Get the first text segment\n        text_segment = text_annotation.segments[0]\n        start_time = text_segment.segment.start_time_offset\n        end_time = text_segment.segment.end_time_offset\n        print(\n            \"start_time: {}, end_time: {}\".format(\n                start_time.seconds + start_time.microseconds * 1e-6,\n                end_time.seconds + end_time.microseconds * 1e-6,\n            )\n        )\n\n        print(\"Confidence: {}\".format(text_segment.confidence))\n\n        # Show the result for the first frame in this segment.\n        frame = text_segment.frames[0]\n        time_offset = frame.time_offset\n        print(\n            \"Time offset for the first frame: {}\".format(\n                time_offset.seconds + time_offset.microseconds * 1e-6\n            )\n        )\n        print(\"Rotated Bounding Box Vertices:\")\n        for vertex in frame.rotated_bounding_box.vertices:\n            print(\"\\tVertex.x: {}, Vertex.y: {}\".format(vertex.x, vertex.y))\n    # [END video_detect_text_gcs]\n\n\n# [START video_detect_text]\ndef video_detect_text(path):\n    \"\"\"Detect text in a local video.\"\"\"\n    video_client = videointelligence.VideoIntelligenceServiceClient()\n    features = [videointelligence.Feature.TEXT_DETECTION]\n    video_context = videointelligence.VideoContext()\n\n    with io.open(path, \"rb\") as file:\n        input_content = file.read()\n\n    operation = video_client.annotate_video(\n        request={\n            \"features\": features,\n            \"input_content\": input_content,\n            \"video_context\": video_context,\n        }\n    )\n\n    print(\"\\nProcessing video for text detection.\")\n    result = operation.result(timeout=300)\n\n    # The first result is retrieved because a single video was processed.\n    annotation_result = result.annotation_results[0]\n\n    for text_annotation in annotation_result.text_annotations:\n        print(\"\\nText: {}\".format(text_annotation.text))\n\n        # Get the first text segment\n        text_segment = text_annotation.segments[0]\n        start_time = text_segment.segment.start_time_offset\n        end_time = text_segment.segment.end_time_offset\n        print(\n            \"start_time: {}, end_time: {}\".format(\n                start_time.seconds + start_time.microseconds * 1e-6,\n                end_time.seconds + end_time.microseconds * 1e-6,\n            )\n        )\n\n        print(\"Confidence: {}\".format(text_segment.confidence))\n\n        # Show the result for the first frame in this segment.\n        frame = text_segment.frames[0]\n        time_offset = frame.time_offset\n        print(\n            \"Time offset for the first frame: {}\".format(\n                time_offset.seconds + time_offset.microseconds * 1e-6\n            )\n        )\n        print(\"Rotated Bounding Box Vertices:\")\n        for vertex in frame.rotated_bounding_box.vertices:\n            print(\"\\tVertex.x: {}, Vertex.y: {}\".format(vertex.x, vertex.y))\n\n\n# [END video_detect_text]\n\n\ndef track_objects_gcs(gcs_uri):\n    # [START video_object_tracking_gcs]\n    \"\"\"Object tracking in a video stored on GCS.\"\"\"\n    from google.cloud import videointelligence\n\n    video_client = videointelligence.VideoIntelligenceServiceClient()\n    features = [videointelligence.Feature.OBJECT_TRACKING]\n    operation = video_client.annotate_video(\n        request={\"features\": features, \"input_uri\": gcs_uri}\n    )\n    print(\"\\nProcessing video for object annotations.\")\n\n    result = operation.result(timeout=500)\n    print(\"\\nFinished processing.\\n\")\n\n    # The first result is retrieved because a single video was processed.\n    object_annotations = result.annotation_results[0].object_annotations\n\n    for object_annotation in object_annotations:\n        print(\"Entity description: {}\".format(object_annotation.entity.description))\n        if object_annotation.entity.entity_id:\n            print(\"Entity id: {}\".format(object_annotation.entity.entity_id))\n\n        print(\n            \"Segment: {}s to {}s\".format(\n                object_annotation.segment.start_time_offset.seconds\n                + object_annotation.segment.start_time_offset.microseconds / 1e6,\n                object_annotation.segment.end_time_offset.seconds\n                + object_annotation.segment.end_time_offset.microseconds / 1e6,\n            )\n        )\n\n        print(\"Confidence: {}\".format(object_annotation.confidence))\n\n        # Here we print only the bounding box of the first frame in the segment\n        frame = object_annotation.frames[0]\n        box = frame.normalized_bounding_box\n        print(\n            \"Time offset of the first frame: {}s\".format(\n                frame.time_offset.seconds + frame.time_offset.microseconds / 1e6\n            )\n        )\n        print(\"Bounding box position:\")\n        print(\"\\tleft  : {}\".format(box.left))\n        print(\"\\ttop   : {}\".format(box.top))\n        print(\"\\tright : {}\".format(box.right))\n        print(\"\\tbottom: {}\".format(box.bottom))\n        print(\"\\n\")\n    # [END video_object_tracking_gcs]\n\n\ndef track_objects(path):\n    # [START video_object_tracking]\n    \"\"\"Object tracking in a local video.\"\"\"\n    from google.cloud import videointelligence\n\n    video_client = videointelligence.VideoIntelligenceServiceClient()\n    features = [videointelligence.Feature.OBJECT_TRACKING]\n\n    with io.open(path, \"rb\") as file:\n        input_content = file.read()\n\n    operation = video_client.annotate_video(\n        request={\"features\": features, \"input_content\": input_content}\n    )\n    print(\"\\nProcessing video for object annotations.\")\n\n    result = operation.result(timeout=500)\n    print(\"\\nFinished processing.\\n\")\n\n    # The first result is retrieved because a single video was processed.\n    object_annotations = result.annotation_results[0].object_annotations\n\n    # Get only the first annotation for demo purposes.\n    object_annotation = object_annotations[0]\n    print(\"Entity description: {}\".format(object_annotation.entity.description))\n    if object_annotation.entity.entity_id:\n        print(\"Entity id: {}\".format(object_annotation.entity.entity_id))\n\n    print(\n        \"Segment: {}s to {}s\".format(\n            object_annotation.segment.start_time_offset.seconds\n            + object_annotation.segment.start_time_offset.microseconds / 1e6,\n            object_annotation.segment.end_time_offset.seconds\n            + object_annotation.segment.end_time_offset.microseconds / 1e6,\n        )\n    )\n\n    print(\"Confidence: {}\".format(object_annotation.confidence))\n\n    # Here we print only the bounding box of the first frame in this segment\n    frame = object_annotation.frames[0]\n    box = frame.normalized_bounding_box\n    print(\n        \"Time offset of the first frame: {}s\".format(\n            frame.time_offset.seconds + frame.time_offset.microseconds / 1e6\n        )\n    )\n    print(\"Bounding box position:\")\n    print(\"\\tleft  : {}\".format(box.left))\n    print(\"\\ttop   : {}\".format(box.top))\n    print(\"\\tright : {}\".format(box.right))\n    print(\"\\tbottom: {}\".format(box.bottom))\n    print(\"\\n\")\n    # [END video_object_tracking]\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(\n        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter\n    )\n    subparsers = parser.add_subparsers(dest=\"command\")\n\n    analyze_labels_parser = subparsers.add_parser(\"labels\", help=analyze_labels.__doc__)\n    analyze_labels_parser.add_argument(\"path\")\n\n    analyze_labels_file_parser = subparsers.add_parser(\n        \"labels_file\", help=analyze_labels_file.__doc__\n    )\n    analyze_labels_file_parser.add_argument(\"path\")\n\n    analyze_explicit_content_parser = subparsers.add_parser(\n        \"explicit_content\", help=analyze_explicit_content.__doc__\n    )\n    analyze_explicit_content_parser.add_argument(\"path\")\n\n    analyze_shots_parser = subparsers.add_parser(\"shots\", help=analyze_shots.__doc__)\n    analyze_shots_parser.add_argument(\"path\")\n\n    transcribe_speech_parser = subparsers.add_parser(\n        \"transcribe\", help=speech_transcription.__doc__\n    )\n    transcribe_speech_parser.add_argument(\"path\")\n\n    detect_text_parser = subparsers.add_parser(\n        \"text_gcs\", help=video_detect_text_gcs.__doc__\n    )\n    detect_text_parser.add_argument(\"path\")\n\n    detect_text_file_parser = subparsers.add_parser(\n        \"text_file\", help=video_detect_text.__doc__\n    )\n    detect_text_file_parser.add_argument(\"path\")\n\n    tack_objects_parser = subparsers.add_parser(\n        \"objects_gcs\", help=track_objects_gcs.__doc__\n    )\n    tack_objects_parser.add_argument(\"path\")\n\n    tack_objects_file_parser = subparsers.add_parser(\n        \"objects_file\", help=track_objects.__doc__\n    )\n    tack_objects_file_parser.add_argument(\"path\")\n\n    args = parser.parse_args()\n\n    if args.command == \"labels\":\n        analyze_labels(args.path)\n    if args.command == \"labels_file\":\n        analyze_labels_file(args.path)\n    if args.command == \"shots\":\n        analyze_shots(args.path)\n    if args.command == \"explicit_content\":\n        analyze_explicit_content(args.path)\n    if args.command == \"transcribe\":\n        speech_transcription(args.path)\n    if args.command == \"text_gcs\":\n        video_detect_text_gcs(args.path)\n    if args.command == \"text_file\":\n        video_detect_text(args.path)\n    if args.command == \"objects_gcs\":\n        track_objects_gcs(args.path)\n    if args.command == \"objects_file\":\n        track_objects(args.path)\n"}}
I0617 07:38:53.053469    6164 server.go:764] jsonrpc2: --> request #0: client/registerCapability: {"registrations":[{"id":"workspace/didChangeConfiguration","method":"workspace/didChangeConfiguration"},{"id":"workspace/didChangeWatchedFiles","method":"workspace/didChangeWatchedFiles","registerOptions":{"watchers":[{"globPattern":"**","kind":2}]}}]}
I0617 07:38:53.053695    6164 server.go:764] jsonrpc2: <-- request #1: workspace/configuration: {"items":[{"section":"cloudcode.aiCompanion"}]}
I0617 07:38:53.059505    6164 server.go:764] jsonrpc2: --> request #1: workspace/configuration: {"items":[{"section":"cloudcode.aiCompanion"}]}
I0617 07:38:53.059588    6164 server.go:764] jsonrpc2: <-- request #2: workspace/configuration: {"items":[{"section":"cloudcode.duetAI"}]}
I0617 07:38:53.060709    6164 server.go:764] jsonrpc2: --> request #2: workspace/configuration: {"items":[{"section":"cloudcode.duetAI"}]}
I0617 07:38:53.060802    6164 server.go:764] jsonrpc2: <-- request #3: workspace/configuration: {"items":[{"section":"geminicodeassist"}]}
I0617 07:38:53.062120    6164 server.go:764] jsonrpc2: --> request #3: workspace/configuration: {"items":[{"section":"geminicodeassist"}]}
I0617 07:38:53.062239    6164 server.go:764] jsonrpc2: <-- request #4: workspace/configuration: {"items":[{"section":"cloudcode"}]}
I0617 07:38:53.064665    6164 server.go:764] jsonrpc2: --> request #4: workspace/configuration: {"items":[{"section":"cloudcode"}]}
I0617 07:38:53.064853    6164 configuration.go:189] product updateChannel will be used
I0617 07:38:53.064913    6164 configuration.go:696] language thresholds: map[]
I0617 07:38:53.064935    6164 configuration.go:637] dataFileExtensions array: [.csv .tsv .jsonl]
I0617 07:38:53.064961    6164 configuration.go:907] atlas codeCompletion llm options: {MaxTokens:64 Temp:0.2 Samples:4 EnablePrompt:<nil> PromptOverride: PostProcess:0xc001478ded StopSequences:map[] DataFilePromptLines:0}
I0617 07:38:53.065044    6164 configuration.go:907] atlas codeGeneration llm options: {MaxTokens:512 Temp:0.2 Samples:4 EnablePrompt:<nil> PromptOverride: PostProcess:0xc001478e0d StopSequences:map[*:[[eod] [EOF] [pre] [suf] [mid]]] DataFilePromptLines:5}
I0617 07:38:53.065220    6164 configuration.go:283] Configured settings for atlasOpts: {"Addr":"","QuotaProject":"","Project":"cloudshell-gca","LogPrompt":true,"UseTypeoverCache":true,"AdaptiveCacheEnabled":false,"InfixCacheEnabled":false,"EnableAdminCitationBlock":false,"EnableAICharactersTelemetry":false,"EnableChatStreaming":false,"Complete":{"MaxTokens":64,"Temp":0.2,"Samples":4,"EnablePrompt":null,"PromptOverride":"","PostProcess":true,"StopSequences":null,"DataFilePromptLines":0},"Generate":{"MaxTokens":512,"Temp":0.2,"Samples":4,"EnablePrompt":null,"PromptOverride":"","PostProcess":true,"StopSequences":{"*":["[eod]","[EOF]","[pre]","[suf]","[mid]"]},"DataFilePromptLines":5},"DataFileExtensions":[".csv",".tsv",".jsonl"]}
I0617 07:38:53.065306    6164 configuration.go:291] Configured settings for cloudCodeOpts: {"Addr":"cloudcode-pa.googleapis.com:443","QuotaProject":"","Project":"cloudshell-gca","LogPrompt":true,"UseTypeoverCache":true,"AdaptiveCacheEnabled":false,"InfixCacheEnabled":false,"EnableAdminCitationBlock":false,"EnableAICharactersTelemetry":false,"EnableChatStreaming":false}
I0617 07:38:53.065320    6164 configuration.go:295] Configured settings for opts: &{trace:true atlasAddr:cloudaicompanion.googleapis.com:443 cloudCodeAddr:cloudcode-pa.googleapis.com:443 cloudCodeQuotaProject: autoGen:false invokeGen:true codeCacheMaxEntries:1024 completionOpts:{debounce:300000000 throttle:100000000 debouncedAfterFetching:false extensionHandlingDebounce:false minScoreThreshold:0 languageThresholds:map[] enableThresholds:true commentCompletion:false citationLengthThreshold:-1 enableRecitations:true citationLogFilePath: repeatedStringFilterThreshold:60 otherFilesGenerationLimit:20 otherFilesGenerationSizeLimit:-1 otherFilesCompletionLimit:0 multiQueryTailNSForCompletion:[] multiQueryTailNSForGeneration:[]} contextExclusionFile:.aiexclude chatOpts:{contextOrdering:fsu maxFileBytes:75000 maxHistoryBytes:500000 escapeContext:false otherFilesLimit:20 otherFilesSizeLimit:-1 userSelectedFilesSizeLimit:-1} useRest:<nil> useCloudCodeAPI:true enableChatStreaming:false enableNotebooks:false enableRAGL:false enableRAGLCompletion:false enableRAGLChat:false enableRAGLCompletionSnippets:false ragLRerankByLangBoost:0 raglCoLocated:20 raglIncludeDocFiles:false raglIncludeUnitTestFile:false raglMaxFileSearchDepth:1 substringsToIdentifyTestPrompts:[test] substringsToIdentifyDocPrompts:[document comment] raglTopKTestFilesToInclude:0 raglTopKDocFilesToInclude:0 raglTokenizationAlgorithm:whitespace raglEnableWaldFileSelection:false raglWaldMaxFileSearchDepth:0}
I0617 07:38:53.065362    6164 configuration.go:297] Configured settings for canCancelRequests: true
I0617 07:38:53.065372    6164 configuration.go:299] Configured settings for contextPromptOpts: &{Endpoint:}
I0617 07:38:53.065399    6164 server.go:764] jsonrpc2: <-- request #5: workspace/configuration: {"items":[{"section":"geminicodeassist.verboseLogging"}]}
I0617 07:38:53.066950    6164 server.go:764] jsonrpc2: --> request #5: workspace/configuration: {"items":[{"section":"geminicodeassist.verboseLogging"}]}
I0617 08:01:11.319929    6164 server.go:764] jsonrpc2: --> request #1: workspace/tierConfiguration: {"userDefinedCloudaicompanionProject":true,"projectId":"cloudshell-gca"}
I0617 08:01:11.320196    6164 server.go:764] jsonrpc2: --> notif: telemetry/sendEvents: {"event_name":"cloudcode.gemini.onboarding.load_code_assist","event_data":{"console_type":"CLOUDCODE_VSCODE","client_email":"f43939714@gmail.com","environment":"PROD"},"metadata":{"cloudcode_event_stack":"cloudcode.gemini.onboarding.load_code_assist","onboard_session_index":"20250617_4","tier_id":"standard-tier","duration_ms":"106.64186799991876","editor_version":"1.99.3-cde","editor_name":"Code OSS for Cloud Shell","ext_name":"googlecloudtools.cloudcode","ext_version":"2.33.0","os_platform":"linux","arch_platform":"x64","os_release":"6.6.87+","change_list":"756317119","built_on":"2025-05-14T22:29:55.638Z","is_cloud_workstations":"false","is_cloud_shell":"true","dependency_state":"unchecked"}}
I0617 08:01:11.320789    6164 tier.go:17] Received tier configuration request: {ProjectID:cloudshell-gca UserDefinedCloudaicompanionProject:true}
I0617 08:01:11.321073    6164 server.go:764] jsonrpc2: <-- request #6: workspace/configuration: {"items":[{"section":"cloudcode.aiCompanion"}]}
I0617 08:01:11.322570    6164 server.go:764] jsonrpc2: --> request #6: workspace/configuration: {"items":[{"section":"cloudcode.aiCompanion"}]}
I0617 08:01:11.322790    6164 server.go:764] jsonrpc2: <-- request #7: workspace/configuration: {"items":[{"section":"cloudcode.duetAI"}]}
I0617 08:01:11.323907    6164 server.go:764] jsonrpc2: --> request #7: workspace/configuration: {"items":[{"section":"cloudcode.duetAI"}]}
I0617 08:01:11.323973    6164 server.go:764] jsonrpc2: <-- request #8: workspace/configuration: {"items":[{"section":"geminicodeassist"}]}
I0617 08:01:11.325383    6164 server.go:764] jsonrpc2: --> request #8: workspace/configuration: {"items":[{"section":"geminicodeassist"}]}
I0617 08:01:11.325487    6164 server.go:764] jsonrpc2: <-- request #9: workspace/configuration: {"items":[{"section":"cloudcode"}]}
I0617 08:01:11.327943    6164 server.go:764] jsonrpc2: --> request #9: workspace/configuration: {"items":[{"section":"cloudcode"}]}
I0617 08:01:11.328189    6164 configuration.go:189] product updateChannel will be used
I0617 08:01:11.328415    6164 configuration.go:696] language thresholds: map[]
I0617 08:01:11.328465    6164 configuration.go:637] dataFileExtensions array: [.csv .tsv .jsonl]
I0617 08:01:11.328500    6164 configuration.go:907] atlas codeCompletion llm options: {MaxTokens:64 Temp:0.2 Samples:4 EnablePrompt:<nil> PromptOverride: PostProcess:0xc001421a6d StopSequences:map[] DataFilePromptLines:0}
I0617 08:01:11.328616    6164 configuration.go:907] atlas codeGeneration llm options: {MaxTokens:512 Temp:0.2 Samples:4 EnablePrompt:<nil> PromptOverride: PostProcess:0xc001421a8d StopSequences:map[*:[[eod] [EOF] [pre] [suf] [mid]]] DataFilePromptLines:5}
I0617 08:01:11.328848    6164 configuration.go:283] Configured settings for atlasOpts: {"Addr":"","QuotaProject":"","Project":"cloudshell-gca","LogPrompt":true,"UseTypeoverCache":true,"AdaptiveCacheEnabled":false,"InfixCacheEnabled":false,"EnableAdminCitationBlock":false,"EnableAICharactersTelemetry":false,"EnableChatStreaming":false,"Complete":{"MaxTokens":64,"Temp":0.2,"Samples":4,"EnablePrompt":null,"PromptOverride":"","PostProcess":true,"StopSequences":null,"DataFilePromptLines":0},"Generate":{"MaxTokens":512,"Temp":0.2,"Samples":4,"EnablePrompt":null,"PromptOverride":"","PostProcess":true,"StopSequences":{"*":["[eod]","[EOF]","[pre]","[suf]","[mid]"]},"DataFilePromptLines":5},"DataFileExtensions":[".csv",".tsv",".jsonl"]}
I0617 08:01:11.328883    6164 configuration.go:291] Configured settings for cloudCodeOpts: {"Addr":"cloudcode-pa.googleapis.com:443","QuotaProject":"","Project":"cloudshell-gca","LogPrompt":true,"UseTypeoverCache":true,"AdaptiveCacheEnabled":false,"InfixCacheEnabled":false,"EnableAdminCitationBlock":false,"EnableAICharactersTelemetry":false,"EnableChatStreaming":false}
I0617 08:01:11.328902    6164 configuration.go:295] Configured settings for opts: &{trace:true atlasAddr:cloudaicompanion.googleapis.com:443 cloudCodeAddr:cloudcode-pa.googleapis.com:443 cloudCodeQuotaProject: autoGen:false invokeGen:true codeCacheMaxEntries:1024 completionOpts:{debounce:300000000 throttle:100000000 debouncedAfterFetching:false extensionHandlingDebounce:false minScoreThreshold:0 languageThresholds:map[] enableThresholds:true commentCompletion:false citationLengthThreshold:-1 enableRecitations:true citationLogFilePath: repeatedStringFilterThreshold:60 otherFilesGenerationLimit:20 otherFilesGenerationSizeLimit:-1 otherFilesCompletionLimit:0 multiQueryTailNSForCompletion:[] multiQueryTailNSForGeneration:[]} contextExclusionFile:.aiexclude chatOpts:{contextOrdering:fsu maxFileBytes:75000 maxHistoryBytes:500000 escapeContext:false otherFilesLimit:20 otherFilesSizeLimit:-1 userSelectedFilesSizeLimit:-1} useRest:<nil> useCloudCodeAPI:true enableChatStreaming:false enableNotebooks:false enableRAGL:false enableRAGLCompletion:false enableRAGLChat:false enableRAGLCompletionSnippets:false ragLRerankByLangBoost:0 raglCoLocated:20 raglIncludeDocFiles:false raglIncludeUnitTestFile:false raglMaxFileSearchDepth:1 substringsToIdentifyTestPrompts:[test] substringsToIdentifyDocPrompts:[document comment] raglTopKTestFilesToInclude:0 raglTopKDocFilesToInclude:0 raglTokenizationAlgorithm:whitespace raglEnableWaldFileSelection:false raglWaldMaxFileSearchDepth:0}
I0617 08:01:11.329031    6164 configuration.go:297] Configured settings for canCancelRequests: true
I0617 08:01:11.329146    6164 configuration.go:299] Configured settings for contextPromptOpts: &{Endpoint:}
I0617 08:01:11.329200    6164 server.go:764] jsonrpc2: <-- request #10: workspace/configuration: {"items":[{"section":"geminicodeassist.verboseLogging"}]}
I0617 08:01:11.331065    6164 server.go:764] jsonrpc2: --> request #10: workspace/configuration: {"items":[{"section":"geminicodeassist.verboseLogging"}]}
I0617 08:01:11.331367    6164 server.go:764] jsonrpc2: <-- result #1: workspace/tierConfiguration: true
I0617 08:02:11.198066    6164 server.go:764] jsonrpc2: --> request #2: workspace/tierConfiguration: {"userDefinedCloudaicompanionProject":true,"projectId":"cloudshell-gca"}
I0617 08:02:11.198802    6164 tier.go:17] Received tier configuration request: {ProjectID:cloudshell-gca UserDefinedCloudaicompanionProject:true}
I0617 08:02:11.198864    6164 server.go:764] jsonrpc2: <-- request #11: workspace/configuration: {"items":[{"section":"cloudcode.aiCompanion"}]}
I0617 08:02:11.198983    6164 server.go:764] jsonrpc2: --> notif: telemetry/sendEvents: {"event_name":"cloudcode.gemini.onboarding.end","event_data":{"console_type":"CLOUDCODE_VSCODE","client_email":"f43939714@gmail.com","environment":"PROD"},"metadata":{"cloudcode_event_stack":"cloudcode.gemini.onboarding.end","onboard_session_index":"20250617_4","total_duration_ms":"59989.600302000064","editor_version":"1.99.3-cde","editor_name":"Code OSS for Cloud Shell","ext_name":"googlecloudtools.cloudcode","ext_version":"2.33.0","os_platform":"linux","arch_platform":"x64","os_release":"6.6.87+","change_list":"756317119","built_on":"2025-05-14T22:29:55.638Z","is_cloud_workstations":"false","is_cloud_shell":"true","tier_id":"standard-tier","dependency_state":"unchecked"}}
I0617 08:02:11.201351    6164 server.go:764] jsonrpc2: --> request #11: workspace/configuration: {"items":[{"section":"cloudcode.aiCompanion"}]}
I0617 08:02:11.201442    6164 server.go:764] jsonrpc2: <-- request #12: workspace/configuration: {"items":[{"section":"cloudcode.duetAI"}]}
I0617 08:02:11.204587    6164 server.go:764] jsonrpc2: --> request #12: workspace/configuration: {"items":[{"section":"cloudcode.duetAI"}]}
I0617 08:02:11.204684    6164 server.go:764] jsonrpc2: <-- request #13: workspace/configuration: {"items":[{"section":"geminicodeassist"}]}
I0617 08:02:11.205953    6164 server.go:764] jsonrpc2: --> request #13: workspace/configuration: {"items":[{"section":"geminicodeassist"}]}
I0617 08:02:11.206050    6164 server.go:764] jsonrpc2: <-- request #14: workspace/configuration: {"items":[{"section":"cloudcode"}]}
I0617 08:02:11.207666    6164 server.go:764] jsonrpc2: --> request #14: workspace/configuration: {"items":[{"section":"cloudcode"}]}
I0617 08:02:11.207838    6164 configuration.go:189] product updateChannel will be used
I0617 08:02:11.207895    6164 configuration.go:696] language thresholds: map[]
I0617 08:02:11.207915    6164 configuration.go:637] dataFileExtensions array: [.csv .tsv .jsonl]
I0617 08:02:11.207940    6164 configuration.go:907] atlas codeCompletion llm options: {MaxTokens:64 Temp:0.2 Samples:4 EnablePrompt:<nil> PromptOverride: PostProcess:0xc001478bbd StopSequences:map[] DataFilePromptLines:0}
I0617 08:02:11.207992    6164 configuration.go:907] atlas codeGeneration llm options: {MaxTokens:512 Temp:0.2 Samples:4 EnablePrompt:<nil> PromptOverride: PostProcess:0xc001478bdd StopSequences:map[*:[[eod] [EOF] [pre] [suf] [mid]]] DataFilePromptLines:5}
I0617 08:02:11.208071    6164 configuration.go:283] Configured settings for atlasOpts: {"Addr":"","QuotaProject":"","Project":"cloudshell-gca","LogPrompt":true,"UseTypeoverCache":true,"AdaptiveCacheEnabled":false,"InfixCacheEnabled":false,"EnableAdminCitationBlock":false,"EnableAICharactersTelemetry":false,"EnableChatStreaming":false,"Complete":{"MaxTokens":64,"Temp":0.2,"Samples":4,"EnablePrompt":null,"PromptOverride":"","PostProcess":true,"StopSequences":null,"DataFilePromptLines":0},"Generate":{"MaxTokens":512,"Temp":0.2,"Samples":4,"EnablePrompt":null,"PromptOverride":"","PostProcess":true,"StopSequences":{"*":["[eod]","[EOF]","[pre]","[suf]","[mid]"]},"DataFilePromptLines":5},"DataFileExtensions":[".csv",".tsv",".jsonl"]}
I0617 08:02:11.208100    6164 configuration.go:291] Configured settings for cloudCodeOpts: {"Addr":"cloudcode-pa.googleapis.com:443","QuotaProject":"","Project":"cloudshell-gca","LogPrompt":true,"UseTypeoverCache":true,"AdaptiveCacheEnabled":false,"InfixCacheEnabled":false,"EnableAdminCitationBlock":false,"EnableAICharactersTelemetry":false,"EnableChatStreaming":false}
I0617 08:02:11.208112    6164 configuration.go:295] Configured settings for opts: &{trace:true atlasAddr:cloudaicompanion.googleapis.com:443 cloudCodeAddr:cloudcode-pa.googleapis.com:443 cloudCodeQuotaProject: autoGen:false invokeGen:true codeCacheMaxEntries:1024 completionOpts:{debounce:300000000 throttle:100000000 debouncedAfterFetching:false extensionHandlingDebounce:false minScoreThreshold:0 languageThresholds:map[] enableThresholds:true commentCompletion:false citationLengthThreshold:-1 enableRecitations:true citationLogFilePath: repeatedStringFilterThreshold:60 otherFilesGenerationLimit:20 otherFilesGenerationSizeLimit:-1 otherFilesCompletionLimit:0 multiQueryTailNSForCompletion:[] multiQueryTailNSForGeneration:[]} contextExclusionFile:.aiexclude chatOpts:{contextOrdering:fsu maxFileBytes:75000 maxHistoryBytes:500000 escapeContext:false otherFilesLimit:20 otherFilesSizeLimit:-1 userSelectedFilesSizeLimit:-1} useRest:<nil> useCloudCodeAPI:true enableChatStreaming:false enableNotebooks:false enableRAGL:false enableRAGLCompletion:false enableRAGLChat:false enableRAGLCompletionSnippets:false ragLRerankByLangBoost:0 raglCoLocated:20 raglIncludeDocFiles:false raglIncludeUnitTestFile:false raglMaxFileSearchDepth:1 substringsToIdentifyTestPrompts:[test] substringsToIdentifyDocPrompts:[document comment] raglTopKTestFilesToInclude:0 raglTopKDocFilesToInclude:0 raglTokenizationAlgorithm:whitespace raglEnableWaldFileSelection:false raglWaldMaxFileSearchDepth:0}
I0617 08:02:11.208155    6164 configuration.go:297] Configured settings for canCancelRequests: true
I0617 08:02:11.208165    6164 configuration.go:299] Configured settings for contextPromptOpts: &{Endpoint:}
I0617 08:02:11.208192    6164 server.go:764] jsonrpc2: <-- request #15: workspace/configuration: {"items":[{"section":"geminicodeassist.verboseLogging"}]}
I0617 08:02:11.208954    6164 server.go:764] jsonrpc2: --> request #15: workspace/configuration: {"items":[{"section":"geminicodeassist.verboseLogging"}]}
I0617 08:02:11.209036    6164 server.go:764] jsonrpc2: <-- result #2: workspace/tierConfiguration: true
I0617 08:02:11.210592    6164 server.go:764] jsonrpc2: --> request #3: service/healthcheck: {"projectID":"cloudshell-gca"}
I0617 08:02:11.210956    6164 cloudcode.go:46] Using Cloud Code API
I0617 08:02:11.219239    6164 client.go:511] CompleteCode request: {"enablePromptEnhancement":true,"ideContext":{"currentFile":{"segments":[{"content":"Code Assist healthcheck id: 9ebe897c-cca2-4919-a949-ba744a028beb\nPi = "},{"isSelected":true},{}]}},"metadata":{"ideName":"Code OSS for Cloud Shell","ideType":"CLOUD_SHELL","ideVersion":"1.99.3-cde","platform":"LINUX_AMD64","pluginType":"CLOUD_CODE","pluginVersion":"2.33.0"},"project":"cloudshell-gca","requestId":"cloudcode-756312233-260cefca-9f22-4f64-9abc-bcb9431946ac"}
I0617 08:02:11.713078    6164 server.go:764] jsonrpc2: <-- result #3: service/healthcheck: null
I0617 08:03:11.199966    6164 server.go:764] jsonrpc2: --> request #4: conversation/startSession: {"preserveHistory":true}
I0617 08:03:11.200494    6164 conversation.go:154] New conversation started, chat history reset
I0617 08:03:11.201757    6164 server.go:764] jsonrpc2: <-- notif: telemetry/event: {"event_name":"cloudcode.aipp.languageserver.conversation.startSession","event_data":{},"metadata":{"config_use_cloudcode_api":"true","config_use_rest":"false","duration_ms":"0","ide_session_index":"20250617_11","ls_session_index":"0","update_channel":"prod","using_channel_defaults":"true"}}
I0617 08:03:11.202603    6164 server.go:764] jsonrpc2: <-- result #4: conversation/startSession: {"history":[],"threadId":"83137105-4b51-11f0-aaf5-46df912dac51"}
I0617 08:03:11.205144    6164 server.go:764] jsonrpc2: --> notif: telemetry/sendEvents: {"event_name":"cloudcode.aipp.languageserver.conversation.startSession","event_data":{"console_type":"CLOUDCODE_VSCODE","client_email":"f43939714@gmail.com","project_id":"cloudshell-gca","environment":"PROD"},"metadata":{"config_use_cloudcode_api":"true","config_use_rest":"false","duration_ms":"0","ide_session_index":"20250617_11","ls_session_index":"0","update_channel":"prod","using_channel_defaults":"true","endpoint":"production","editor_version":"1.99.3-cde","editor_name":"Code OSS for Cloud Shell","ext_name":"googlecloudtools.cloudcode","ext_version":"2.33.0","os_platform":"linux","arch_platform":"x64","os_release":"6.6.87+","change_list":"756317119","built_on":"2025-05-14T22:29:55.638Z","is_cloud_workstations":"false","is_cloud_shell":"true","tier_id":"standard-tier","dependency_state":"unchecked"}}
I0617 08:04:11.295960    6164 server.go:764] jsonrpc2: --> request #5: conversation/suggestions: {}
I0617 08:04:11.296234    6164 server.go:764] jsonrpc2: <-- notif: telemetry/event: {"event_name":"cloudcode.aipp.languageserver.conversation.suggestions","event_data":{},"metadata":{"config_use_cloudcode_api":"true","config_use_rest":"false","duration_ms":"0","ide_session_index":"20250617_11","ls_session_index":"0","update_channel":"prod","using_channel_defaults":"true"}}
I0617 08:04:11.296366    6164 server.go:764] jsonrpc2: <-- result #5: conversation/suggestions: {"items":null}
I0617 08:04:11.302543    6164 server.go:764] jsonrpc2: --> notif: telemetry/sendEvents: {"event_name":"cloudcode.aipp.languageserver.conversation.suggestions","event_data":{"console_type":"CLOUDCODE_VSCODE","client_email":"f43939714@gmail.com","project_id":"cloudshell-gca","environment":"PROD"},"metadata":{"config_use_cloudcode_api":"true","config_use_rest":"false","duration_ms":"0","ide_session_index":"20250617_11","ls_session_index":"0","update_channel":"prod","using_channel_defaults":"true","endpoint":"production","editor_version":"1.99.3-cde","editor_name":"Code OSS for Cloud Shell","ext_name":"googlecloudtools.cloudcode","ext_version":"2.33.0","os_platform":"linux","arch_platform":"x64","os_release":"6.6.87+","change_list":"756317119","built_on":"2025-05-14T22:29:55.638Z","is_cloud_workstations":"false","is_cloud_shell":"true","tier_id":"standard-tier","dependency_state":"unchecked"}}
